{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53d0cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /usr/lib/python3/dist-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.56.0)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in ./.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2025.8.29)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/lib/python3/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install transformers torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c59d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebea446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_HOME: Not set\n",
      "PATH: /usr/bin:/home/ubuntu/.vscode-server/cli/servers/Stable-c306e94f98122556ca081f527b466015e1bc37b0/server/bin/remote-cli:/home/ubuntu/.local/bin:/home/ubuntu/.local/bin:/usr/mpi/gcc/openmpi-4.1.7rc1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/.vscode-server/cli/servers/Stable-c306e94f98122556ca081f527b466015e1bc37b0/server/bin/remote-cli:/home/ubuntu/.local/bin:/home/ubuntu/.local/bin:/usr/mpi/gcc/openmpi-4.1.7rc1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "LD_LIBRARY_PATH: /usr/mpi/gcc/openmpi-4.1.7rc1/lib:/usr/mpi/gcc/openmpi-4.1.7rc1/lib64\n",
      "PyTorch version: 2.8.0+cpu\n",
      "PyTorch CUDA version: None\n",
      "Is CUDA build: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CUDA_HOME:\", os.environ.get('CUDA_HOME', 'Not set'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))\n",
    "print(\"LD_LIBRARY_PATH:\", os.environ.get('LD_LIBRARY_PATH', 'Not set'))\n",
    "\n",
    "# Check PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Is CUDA build: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969aa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda'\n",
    "os.environ['PATH'] = '/usr/local/cuda/bin:' + os.environ.get('PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62adf3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0\n",
      "Uninstalling torch-2.8.0:\n",
      "  Successfully uninstalled torch-2.8.0\n",
      "Found existing installation: torchvision 0.22.0\n",
      "Not uninstalling torchvision at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "Can't uninstall 'torchvision'. No files were found to uninstall.\n",
      "Found existing installation: torchaudio 2.8.0\n",
      "Uninstalling torchaudio-2.8.0:\n",
      "  Successfully uninstalled torchaudio-2.8.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (0.22.0)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/torchaudio-2.2.0-cp310-cp310-linux_aarch64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 156.0 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/torchaudio-2.1.2-cp310-cp310-linux_aarch64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 175.9 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/torchaudio-2.1.1-cp310-cp310-linux_aarch64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 232.0 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/torchaudio-2.1.0-cp310-cp310-linux_aarch64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 67.9 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/torchaudio-2.0.2-cp310-cp310-manylinux2014_aarch64.whl (4.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 122.1 MB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/torch-2.0.1-cp310-cp310-manylinux2014_aarch64.whl (74.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 MB 108.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in /usr/lib/python3/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchaudio\n",
      "Successfully installed torch-2.0.1 torchaudio-2.0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the CUDA environment issue, we can reinstall PyTorch with the correct CUDA version.\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Uninstall current PyTorch\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"torchaudio\", \"-y\"])\n",
    "\n",
    "# Install CUDA version\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cbfdc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 512\n",
    "EMBED_DIM = 256\n",
    "NUM_ITERS = 4\n",
    "ALPHA = 0.5\n",
    "LR = 5e-5\n",
    "EPOCHS = 10\n",
    "MAX_LENGTH = 4096 # Maximum token length for padding/truncation\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_TO_MULTIPLE_OF=8\n",
    "GRADIENT_CLIPPING = 1.0\n",
    "\n",
    "# Test if CUDA is available\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d22c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AG News dataset\n",
    "dataset = load_dataset('ag_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161a80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",\n",
    "                                          padding=\"max_length\",\n",
    "                                          truncation=True,\n",
    "                                          max_length=MAX_LENGTH,\n",
    "                                          pad_to_multiple_of=PAD_TO_MULTIPLE_OF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e2090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7574e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b225ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_texts = dataset['train']['text']\n",
    "train_labels = label_encoder.transform(dataset['train']['label'])\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = label_encoder.transform(dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab969d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AGNewsDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "test_dataset = AGNewsDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=12, pin_memory=True,\n",
    "                          prefetch_factor=4,\n",
    "                          persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edcb3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a validation set before training start\n",
    "import random\n",
    "\n",
    "# Select a small random subset from our test dataset\n",
    "subset_size = 10  # Adjust as needed\n",
    "subset_indices = random.sample(range(len(test_loader.dataset)), subset_size)\n",
    "\n",
    "# Create a new DataLoader for this subset\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "test_subset = Subset(test_loader.dataset, subset_indices)\n",
    "test_subset_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665a9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 2: Define the Model ==========\n",
    "class DiffusionAttentionFreeModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_iters=NUM_ITERS, alpha=ALPHA, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.noise_std = 0.1  # Initial noise\n",
    "        self.alpha = alpha  # Decay factor\n",
    "        self.num_iters = num_iters  # Iterative updates\n",
    "        self.update_mlp = nn.Linear(embed_dim, embed_dim)  # Local transformation\n",
    "        self.output_mlp = nn.Linear(embed_dim, num_classes)  # Classifier\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Step 1: Embed + Add Noise\n",
    "        h = self.embedding(input_ids) + self.noise_std * torch.randn_like(self.embedding(input_ids))\n",
    "\n",
    "        # Step 2: Iterative Refinement (Diffusion Process)\n",
    "        for _ in range(self.num_iters):\n",
    "            # Multi-Neighbor Updates\n",
    "            h_left = torch.roll(h, shifts=1, dims=1)\n",
    "            h_right = torch.roll(h, shifts=-1, dims=1)\n",
    "            h_update = self.update_mlp(h_left) + self.update_mlp(h_right)\n",
    "\n",
    "            # Weighted update rule (diffusion-like)\n",
    "            h = self.alpha * h + (1 - self.alpha) * h_update\n",
    "\n",
    "        # Step 3: Pooling + Classification\n",
    "        h = (h * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)  # Masked mean pooling\n",
    "        logits = self.output_mlp(h)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7566b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / len(test_loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa18750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 5e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning rate\", LR)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "diff_model = DiffusionAttentionFreeModel(vocab_size, EMBED_DIM).to(DEVICE)\n",
    "optimizer = optim.AdamW(diff_model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443d1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: Load Time = 0.0000 sec\n",
      "Batch 2: Load Time = 0.0001 sec\n",
      "Batch 3: Load Time = 0.0001 sec\n",
      "Batch 4: Load Time = 0.0001 sec\n",
      "Batch 5: Load Time = 0.0001 sec\n",
      "Batch 6: Load Time = 0.0001 sec\n",
      "Batch 7: Load Time = 0.0001 sec\n",
      "Batch 8: Load Time = 0.0001 sec\n",
      "Batch 9: Load Time = 0.0001 sec\n",
      "Batch 10: Load Time = 0.0001 sec\n",
      "Batch 11: Load Time = 0.0001 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i, batch in enumerate(train_loader):\n",
    "    start_time = time.time()\n",
    "    batch_data = batch[\"input_ids\"].to(DEVICE)  # Load batch to GPU\n",
    "    print(f\"Batch {i+1}: Load Time = {time.time() - start_time:.4f} sec\")\n",
    "\n",
    "    if i == 10:  # Stop after 10 batches\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19be5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedDiffusionAttentionFreeModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_iters=4, alpha=0.7, num_classes=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_iters = num_iters\n",
    "        self.alpha = alpha\n",
    "        self.noise_std = 0.05  # Reduced for FP16 stability\n",
    "        \n",
    "        # Token embedding with proper initialization\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # Multi-head neighbor interaction (more sophisticated than single MLP)\n",
    "        self.neighbor_proj = nn.ModuleList([\n",
    "            nn.Linear(embed_dim, embed_dim, bias=False) for _ in range(3)\n",
    "        ])  # left, right, self projections\n",
    "        \n",
    "        # Layer normalization for stability\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Nonlinear transformation with residual connection\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(embed_dim * 2, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # Classification head with dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights for FP16 stability\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Proper weight initialization for FP16 training\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                # Xavier initialization scaled for FP16\n",
    "                nn.init.xavier_normal_(module.weight, gain=0.02)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "                nn.init.constant_(module.weight, 1.0)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        # Step 1: Embed + Add controlled noise\n",
    "        h = self.embedding(input_ids)\n",
    "        \n",
    "        if self.training:\n",
    "            # Add noise only during training, with proper scaling\n",
    "            noise = torch.randn_like(h, dtype=h.dtype, device=h.device) * self.noise_std\n",
    "            h = h + noise\n",
    "        \n",
    "        # Step 2: Iterative refinement with proper neighbor handling\n",
    "        for iteration in range(self.num_iters):\n",
    "            # Get neighbor representations\n",
    "            h_left = torch.cat([h[:, -1:, :], h[:, :-1, :]], dim=1)  # Proper circular shift\n",
    "            h_right = torch.cat([h[:, 1:, :], h[:, :1, :]], dim=1)   # Proper circular shift\n",
    "            \n",
    "            # Apply different projections to each neighbor type\n",
    "            h_left_proj = self.neighbor_proj[0](h_left)\n",
    "            h_right_proj = self.neighbor_proj[1](h_right)\n",
    "            h_self_proj = self.neighbor_proj[2](h)\n",
    "            \n",
    "            # Combine neighbor information\n",
    "            neighbor_sum = h_left_proj + h_right_proj + h_self_proj\n",
    "            \n",
    "            # Apply nonlinear transformation\n",
    "            h_update = self.update_mlp(neighbor_sum)\n",
    "            \n",
    "            # Residual connection + weighted update\n",
    "            h_new = self.alpha * h + (1 - self.alpha) * h_update\n",
    "            \n",
    "            # Apply layer normalization for stability\n",
    "            h = self.layer_norm(h_new)\n",
    "        \n",
    "        # Step 3: Masked pooling (handle padding properly)\n",
    "        if attention_mask is not None:\n",
    "            # Expand attention mask for broadcasting\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).float()\n",
    "            h_masked = h * mask_expanded\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            mask_sum = mask_expanded.sum(dim=1).clamp(min=1e-8)\n",
    "            pooled = h_masked.sum(dim=1) / mask_sum\n",
    "        else:\n",
    "            pooled = h.mean(dim=1)\n",
    "        \n",
    "        # Step 4: Classification\n",
    "        logits = self.classifier(pooled)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f821521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_improved_model(model, train_loader, test_loader, device, \n",
    "                        epochs=50, lr=5e-5, checkpoint_path=\"./checkpoints\"):\n",
    "    \"\"\"\n",
    "    Training function with proper FP16 support and gradient scaling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure checkpoint directory exists\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    \n",
    "    # Initialize optimizer with FP16-friendly settings\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=lr,\n",
    "        weight_decay=0.01,\n",
    "        eps=1e-8  # Increased epsilon for FP16 numerical stability\n",
    "    )\n",
    "    \n",
    "    # Initialize gradient scaler for mixed precision\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=5 \n",
    "    )\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    latest_checkpoint = os.path.join(checkpoint_path, \"latest_model.pth\")\n",
    "    initial_epoch = 1\n",
    "    \n",
    "    if os.path.exists(latest_checkpoint):\n",
    "        print(\"Loading checkpoint...\")\n",
    "        checkpoint = torch.load(latest_checkpoint, weights_only=False)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        initial_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\"Resuming training from epoch {initial_epoch}\")\n",
    "    \n",
    "    # Training loop\n",
    "    log_file = os.path.join(checkpoint_path, f\"training_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "    \n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(f\"=== Training Start - {datetime.datetime.now()} ===\\n\")\n",
    "        f.write(f\"Model: ImprovedDiffusionAttentionFreeModel\\n\")\n",
    "        f.write(f\"Learning Rate: {lr}\\n\")\n",
    "        f.write(f\"Epochs: {epochs}\\n\")\n",
    "        f.write(f\"Initial Scaler Scale: {scaler.get_scale()}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        for epoch in range(initial_epoch, epochs + 1):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Training phase\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total_samples = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass with autocast for mixed precision\n",
    "                with autocast('cuda'):\n",
    "                    outputs = model(input_ids, attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Check for loss explosion early\n",
    "                if loss.item() > 100:\n",
    "                    print(f\"WARNING: Loss explosion detected: {loss.item():.2f}\")\n",
    "                    print(f\"Scaler scale: {scaler.get_scale()}\")\n",
    "                    f.write(f\"WARNING: Loss explosion at epoch {epoch}, batch {batch_idx}\\n\")\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient clipping (unscale first)\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Optimizer step\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                # Statistics\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Log progress every 50 batches\n",
    "                if batch_idx % 50 == 0:\n",
    "                    current_acc = 100. * correct / total_samples\n",
    "                    print(f\"Epoch {epoch}, Batch {batch_idx}: Loss = {loss.item():.4f}, Acc = {current_acc:.2f}%\")\n",
    "            \n",
    "            epoch_time = time.time() - start_time\n",
    "            train_accuracy = correct / total_samples\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            \n",
    "            # Evaluation phase\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "                    \n",
    "                    with autocast('cuda'):\n",
    "                        outputs = model(input_ids, attention_mask)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    test_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            test_accuracy = test_correct / test_total\n",
    "            avg_test_loss = test_loss / len(test_loader)\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(avg_test_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scaler_state_dict\": scaler.state_dict(),\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"test_loss\": avg_test_loss,\n",
    "                \"train_acc\": train_accuracy,\n",
    "                \"test_acc\": test_accuracy,\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint, latest_checkpoint)\n",
    "            if epoch % 5 == 0:  # Save every 5 epochs\n",
    "                torch.save(checkpoint, os.path.join(checkpoint_path, f\"model_epoch_{epoch}.pth\"))\n",
    "            \n",
    "            # Logging\n",
    "            log_msg = f\"Epoch {epoch}/{epochs}:\\n\"\n",
    "            log_msg += f\"  Train - Loss: {avg_train_loss:.4f}, Acc: {train_accuracy:.4f}\\n\"\n",
    "            log_msg += f\"  Test  - Loss: {avg_test_loss:.4f}, Acc: {test_accuracy:.4f}\\n\"\n",
    "            log_msg += f\"  Time: {epoch_time:.2f}s, LR: {current_lr:.2e}\\n\"\n",
    "            log_msg += f\"  Scaler Scale: {scaler.get_scale()}\\n\"\n",
    "            log_msg += \"-\" * 50 + \"\\n\"\n",
    "            \n",
    "            print(log_msg)\n",
    "            f.write(log_msg)\n",
    "            f.flush()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718c65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_improved_training():\n",
    "    \"\"\"\n",
    "    Setup function to replace your current training loop\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your existing hyperparameters\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    EMBED_DIM = 256\n",
    "    NUM_ITERS = 4\n",
    "    ALPHA = 0.7  # Increased from 0.5 for better stability\n",
    "    LR = 2e-5    # Reduced from 5e-5 for FP16 stability\n",
    "    EPOCHS = 10\n",
    "    \n",
    "    # Initialize improved model\n",
    "    vocab_size = 30522  # Your tokenizer vocab size\n",
    "    model = ImprovedDiffusionAttentionFreeModel(\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        num_iters=NUM_ITERS,\n",
    "        alpha=ALPHA,\n",
    "        num_classes=4\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Convert to half precision\n",
    "    model = model.half()\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Model size (MB): {sum(p.numel() * p.element_size() for p in model.parameters()) / 1024**2:.2f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f82caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, test_loader, tokenizer):\n",
    "    \"\"\"\n",
    "    Drop-in replacement for your current training cell\n",
    "    \"\"\"\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create improved model\n",
    "    model = ImprovedDiffusionAttentionFreeModel(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        embed_dim=256,  # Your EMBED_DIM\n",
    "        num_iters=4,    # Your NUM_ITERS  \n",
    "        alpha=0.7,      # Improved from your 0.5\n",
    "        num_classes=4\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Convert to FP16 - Removing this for the time being\n",
    "    #model = model.half()\n",
    "    \n",
    "    # Start training with proper FP16 support\n",
    "    trained_model = train_improved_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=DEVICE,\n",
    "        epochs=5,\n",
    "        lr=2e-5,  # Reduced for FP16 stability\n",
    "        checkpoint_path=\"./checkpoints_improved\"\n",
    "    )\n",
    "    \n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59247c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.amp import autocast, GradScaler  # Updated API\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "train(train_loader, test_loader, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162bad96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
