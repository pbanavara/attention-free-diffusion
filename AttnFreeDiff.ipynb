{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1YRGHbwi-7_M6bcQqfLekc96Z3_SKIfGG",
      "authorship_tag": "ABX9TyPdQwpBvH7jB9HZFXZ3Ce3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbanavara/experimental_attention_free_diff/blob/main/AttnFreeDiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAP_HFUjs5GI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diffusion Model"
      ],
      "metadata": {
        "trusted": true,
        "id": "DiT_yfvrbbd-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40zbYSefnmAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9eTWVZjtRQx",
        "outputId": "907a2501-4dab-4ecb-9066-cd339a853a72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:52:41.917173Z",
          "iopub.execute_input": "2025-02-24T18:52:41.917572Z",
          "iopub.status.idle": "2025-02-24T18:52:46.375625Z",
          "shell.execute_reply.started": "2025-02-24T18:52:41.917537Z",
          "shell.execute_reply": "2025-02-24T18:52:46.374788Z"
        },
        "id": "djZxo5vnbbd7"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512"
      ],
      "metadata": {
        "id": "geBBtMbPGKk3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Hyperparameters ==========\n",
        "EMBED_DIM = 256\n",
        "NUM_ITERS = 4\n",
        "ALPHA = 0.5\n",
        "LR = 5e-5\n",
        "EPOCHS = 10\n",
        "MAX_LENGTH = 4096 # Maximum token length for padding/truncation\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PAD_TO_MULTIPLE_OF=8\n",
        "GRADIENT_CLIPPING = 1.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:52:49.910847Z",
          "iopub.execute_input": "2025-02-24T18:52:49.911145Z",
          "iopub.status.idle": "2025-02-24T18:52:49.959409Z",
          "shell.execute_reply.started": "2025-02-24T18:52:49.911124Z",
          "shell.execute_reply": "2025-02-24T18:52:49.958402Z"
        },
        "id": "CrTfV-_5bbd8"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": [
        "# Load AG News dataset\n",
        "dataset = load_dataset('ag_news')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:52:51.221737Z",
          "iopub.execute_input": "2025-02-24T18:52:51.222048Z",
          "iopub.status.idle": "2025-02-24T18:52:52.993665Z",
          "shell.execute_reply.started": "2025-02-24T18:52:51.222024Z",
          "shell.execute_reply": "2025-02-24T18:52:52.993007Z"
        },
        "id": "eAdVpK3lbbd8"
      },
      "outputs": [],
      "execution_count": 77
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",\n",
        "                                          padding=\"max_length\",\n",
        "                                          truncation=True,\n",
        "                                          max_length=MAX_LENGTH,\n",
        "                                          pad_to_multiple_of=PAD_TO_MULTIPLE_OF)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:02.665297Z",
          "iopub.execute_input": "2025-02-24T18:53:02.66564Z",
          "iopub.status.idle": "2025-02-24T18:53:02.762311Z",
          "shell.execute_reply.started": "2025-02-24T18:53:02.665614Z",
          "shell.execute_reply": "2025-02-24T18:53:02.761545Z"
        },
        "id": "qu-QfK5jbbd8"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(dataset['train']['label'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:04.008524Z",
          "iopub.execute_input": "2025-02-24T18:53:04.008839Z",
          "iopub.status.idle": "2025-02-24T18:53:04.069967Z",
          "shell.execute_reply.started": "2025-02-24T18:53:04.008814Z",
          "shell.execute_reply": "2025-02-24T18:53:04.069174Z"
        },
        "id": "gOBfDhkdbbd9",
        "outputId": "0e9b8a89-a931-4e2b-a798-301065effcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-6 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-6 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-6 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-6 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-6 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset Class\n",
        "class AGNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:08.540133Z",
          "iopub.execute_input": "2025-02-24T18:53:08.540459Z",
          "iopub.status.idle": "2025-02-24T18:53:08.546836Z",
          "shell.execute_reply.started": "2025-02-24T18:53:08.540432Z",
          "shell.execute_reply": "2025-02-24T18:53:08.545837Z"
        },
        "id": "9W03cHY7bbd9"
      },
      "outputs": [],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets\n",
        "train_texts = dataset['train']['text']\n",
        "train_labels = label_encoder.transform(dataset['train']['label'])\n",
        "test_texts = dataset['test']['text']\n",
        "test_labels = label_encoder.transform(dataset['test']['label'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:09.850372Z",
          "iopub.execute_input": "2025-02-24T18:53:09.850678Z",
          "iopub.status.idle": "2025-02-24T18:53:10.062302Z",
          "shell.execute_reply.started": "2025-02-24T18:53:09.850655Z",
          "shell.execute_reply": "2025-02-24T18:53:10.061627Z"
        },
        "id": "JLe_IxI7bbd9"
      },
      "outputs": [],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AGNewsDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
        "test_dataset = AGNewsDataset(test_texts, test_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=12, pin_memory=True,\n",
        "                          prefetch_factor=4,\n",
        "                          persistent_workers=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:12.133233Z",
          "iopub.execute_input": "2025-02-24T18:53:12.133607Z",
          "iopub.status.idle": "2025-02-24T18:53:12.137958Z",
          "shell.execute_reply.started": "2025-02-24T18:53:12.13358Z",
          "shell.execute_reply": "2025-02-24T18:53:12.13713Z"
        },
        "id": "mWqVKcNBbbd9"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a validation set before training start\n",
        "import random\n",
        "\n",
        "# Select a small random subset from our test dataset\n",
        "subset_size = 10  # Adjust as needed\n",
        "subset_indices = random.sample(range(len(test_loader.dataset)), subset_size)\n",
        "\n",
        "# Create a new DataLoader for this subset\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "test_subset = Subset(test_loader.dataset, subset_indices)\n",
        "test_subset_loader = DataLoader(test_subset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "cKK7hBFI1A57"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Step 2: Define the Model ==========\n",
        "class DiffusionAttentionFreeModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_iters=NUM_ITERS, alpha=ALPHA, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.noise_std = 0.1  # Initial noise\n",
        "        self.alpha = alpha  # Decay factor\n",
        "        self.num_iters = num_iters  # Iterative updates\n",
        "        self.update_mlp = nn.Linear(embed_dim, embed_dim)  # Local transformation\n",
        "        self.output_mlp = nn.Linear(embed_dim, num_classes)  # Classifier\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Step 1: Embed + Add Noise\n",
        "        h = self.embedding(input_ids) + self.noise_std * torch.randn_like(self.embedding(input_ids))\n",
        "\n",
        "        # Step 2: Iterative Refinement (Diffusion Process)\n",
        "        for _ in range(self.num_iters):\n",
        "            # Multi-Neighbor Updates\n",
        "            h_left = torch.roll(h, shifts=1, dims=1)\n",
        "            h_right = torch.roll(h, shifts=-1, dims=1)\n",
        "            h_update = self.update_mlp(h_left) + self.update_mlp(h_right)\n",
        "\n",
        "            # Weighted update rule (diffusion-like)\n",
        "            h = self.alpha * h + (1 - self.alpha) * h_update\n",
        "\n",
        "        # Step 3: Pooling + Classification\n",
        "        h = (h * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)  # Masked mean pooling\n",
        "        logits = self.output_mlp(h)\n",
        "        return logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:13.819637Z",
          "iopub.execute_input": "2025-02-24T18:53:13.819931Z",
          "iopub.status.idle": "2025-02-24T18:53:13.82991Z",
          "shell.execute_reply.started": "2025-02-24T18:53:13.819908Z",
          "shell.execute_reply": "2025-02-24T18:53:13.829104Z"
        },
        "id": "fRawtnDBbbd9"
      },
      "outputs": [],
      "execution_count": 84
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            labels = batch['label'].to(DEVICE)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(test_loader), correct / total"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:25.191982Z",
          "iopub.execute_input": "2025-02-24T18:53:25.192355Z",
          "iopub.status.idle": "2025-02-24T18:53:25.198004Z",
          "shell.execute_reply.started": "2025-02-24T18:53:25.192316Z",
          "shell.execute_reply": "2025-02-24T18:53:25.196912Z"
        },
        "id": "zW413Yarbbd9"
      },
      "outputs": [],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Learning rate\", LR)\n",
        "vocab_size = tokenizer.vocab_size\n",
        "diff_model = DiffusionAttentionFreeModel(vocab_size, EMBED_DIM).to(DEVICE)\n",
        "optimizer = optim.AdamW(diff_model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T18:53:27.76256Z",
          "iopub.execute_input": "2025-02-24T18:53:27.762859Z",
          "iopub.status.idle": "2025-02-24T18:53:27.995792Z",
          "shell.execute_reply.started": "2025-02-24T18:53:27.762836Z",
          "shell.execute_reply": "2025-02-24T18:53:27.9951Z"
        },
        "id": "1_pwE6Ltbbd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28901b11-4386-4918-af07-bc6ef97176a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate 5e-05\n"
          ]
        }
      ],
      "execution_count": 86
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for i, batch in enumerate(train_loader):\n",
        "    start_time = time.time()\n",
        "    batch_data = batch[\"input_ids\"].to(DEVICE)  # Load batch to GPU\n",
        "    print(f\"Batch {i+1}: Load Time = {time.time() - start_time:.4f} sec\")\n",
        "\n",
        "    if i == 10:  # Stop after 10 batches\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xjPZWSaDYz8",
        "outputId": "7a9003ed-ef50-4ceb-bc1c-9fe3cd668c86"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: Load Time = 0.0017 sec\n",
            "Batch 2: Load Time = 0.0015 sec\n",
            "Batch 3: Load Time = 0.0015 sec\n",
            "Batch 4: Load Time = 0.0016 sec\n",
            "Batch 5: Load Time = 0.0014 sec\n",
            "Batch 6: Load Time = 0.0015 sec\n",
            "Batch 7: Load Time = 0.0014 sec\n",
            "Batch 8: Load Time = 0.0016 sec\n",
            "Batch 9: Load Time = 0.0015 sec\n",
            "Batch 10: Load Time = 0.0014 sec\n",
            "Batch 11: Load Time = 0.0014 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import datetime\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import time\n",
        "\n",
        "EPOCHS = 50\n",
        "# Define hyperparameters\n",
        "checkpoint_path = \"drive/MyDrive/model_checkpoints\"\n",
        "\n",
        "# Ensure checkpoint directory exists\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "# Initialize Model & Optimizer\n",
        "vocab_size = tokenizer.vocab_size\n",
        "diff_model = DiffusionAttentionFreeModel(vocab_size, EMBED_DIM).to(DEVICE)\n",
        "optimizer = optim.AdamW(diff_model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning Rate Scheduler (Reduce LR when validation loss stops improving)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Load previous checkpoint if exists\n",
        "latest_checkpoint = os.path.join(checkpoint_path, \"latest_model.pth\")\n",
        "if os.path.exists(latest_checkpoint):\n",
        "    print(\"Loading checkpoint...\")\n",
        "    checkpoint = torch.load(latest_checkpoint)\n",
        "    diff_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    initial_epoch = checkpoint[\"epoch\"] + 1\n",
        "    print(f\"Resuming training from epoch {initial_epoch}\")\n",
        "else:\n",
        "    initial_epoch = 1\n",
        "\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True  # Enables Tensor Cores for faster FP16\n",
        "\n",
        "# Training loop\n",
        "with open(os.path.join(checkpoint_path,\n",
        "    \"training_log_\" + str(datetime.datetime.now()) + \".txt\"), \"a\") as f:  # Open once to avoid multiple file creations\n",
        "    f.write(f\"\\n=== Training Start - {datetime.datetime.now()} ===\\n\")\n",
        "    f.write(f\"Batch Size: {BATCH_SIZE}\\n\")\n",
        "    f.write(f\"Max Sequence Length: {MAX_LENGTH}\\n\")\n",
        "    #f.write(f\"Gradient Clipping: {gradient_clipping if gradient_clipping else 'None'}\\n\")\n",
        "    f.write(f\"Number of Epochs: {EPOCHS}\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\")\n",
        "    for epoch in range(initial_epoch, EPOCHS + 1):\n",
        "        start_time = time.time()\n",
        "        diff_model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "            texts = batch[\"input_ids\"].to(DEVICE)\n",
        "            masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():  # FP16 Mixed Precision\n",
        "                output = diff_model(input_ids=texts, attention_mask=masks)\n",
        "                loss = criterion(output, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if GRADIENT_CLIPPING:\n",
        "                torch.nn.utils.clip_grad_norm_(diff_model.parameters(), max_norm=GRADIENT_CLIPPING)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (output.argmax(dim=1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        accuracy = correct / total\n",
        "\n",
        "        # Save checkpoint after every epoch\n",
        "        checkpoint = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": diff_model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(checkpoint_path, \"latest_model.pth\"))\n",
        "        torch.save(checkpoint, os.path.join(checkpoint_path, f\"model_epoch_{epoch}.pth\"))  # Save per epoch\n",
        "\n",
        "        # Adjust learning rate based on validation loss\n",
        "        test_loss, test_acc = evaluate(diff_model, test_loader, criterion)\n",
        "        scheduler.step(test_loss)  # Reduce LR if validation loss plateaus\n",
        "\n",
        "        print(f\"Epoch {epoch} - Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}, Time: {epoch_time:.2f} sec\")\n",
        "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        # Write to the log file\n",
        "        f.write(f\"\\n=== Epoch {epoch+1} - {datetime.datetime.now()} ===\\n\")\n",
        "        f.write(f\"Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}, Time: {epoch_time:.2f} sec\\n\")\n",
        "\n",
        "        # Append GPU stats\n",
        "        f.write(os.popen(\"nvidia-smi\").read())  # More efficient than os.system\n",
        "        f.flush()  # Ensure data is written immediately\n",
        "        # Log learning rate\n",
        "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        f.write(f\"Current Learning Rate: {current_lr:.8f}\")\n",
        "        print(f\"Current Learning Rate: {current_lr:.8f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5otnswHBwE",
        "outputId": "e19a8f9f-64bc-4a22-a8ca-4498c60175de"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-9bd027d6ec52>:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-92-9bd027d6ec52>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(latest_checkpoint)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n",
            "Resuming training from epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-9bd027d6ec52>:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # FP16 Mixed Precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Loss: 158.4427, Accuracy: 0.7477, Time: 80.65 sec\n",
            "Test Loss: 0.6858, Test Accuracy: 0.7428\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 42 - Loss: 157.3184, Accuracy: 0.7496, Time: 80.86 sec\n",
            "Test Loss: 0.6796, Test Accuracy: 0.7471\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 43 - Loss: 156.3316, Accuracy: 0.7517, Time: 80.73 sec\n",
            "Test Loss: 0.6784, Test Accuracy: 0.7442\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 44 - Loss: 155.4265, Accuracy: 0.7537, Time: 80.99 sec\n",
            "Test Loss: 0.6727, Test Accuracy: 0.7492\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 45 - Loss: 154.3936, Accuracy: 0.7563, Time: 81.02 sec\n",
            "Test Loss: 0.6691, Test Accuracy: 0.7471\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 46 - Loss: 153.4276, Accuracy: 0.7573, Time: 80.89 sec\n",
            "Test Loss: 0.6667, Test Accuracy: 0.7501\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 47 - Loss: 152.6161, Accuracy: 0.7588, Time: 80.68 sec\n",
            "Test Loss: 0.6610, Test Accuracy: 0.7541\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 48 - Loss: 151.6926, Accuracy: 0.7609, Time: 80.79 sec\n",
            "Test Loss: 0.6566, Test Accuracy: 0.7550\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 49 - Loss: 150.7512, Accuracy: 0.7625, Time: 80.89 sec\n",
            "Test Loss: 0.6534, Test Accuracy: 0.7542\n",
            "Current Learning Rate: 0.00005000\n",
            "Epoch 50 - Loss: 149.9754, Accuracy: 0.7641, Time: 80.73 sec\n",
            "Test Loss: 0.6526, Test Accuracy: 0.7575\n",
            "Current Learning Rate: 0.00005000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on our own test subset\n",
        "final_subset_loss, final_subset_acc = evaluate(diff_model, test_subset_loader, criterion)\n",
        "\n",
        "print(f\"🔥 Test Subset Loss: {final_subset_loss:.4f}, Test Accuracy: {final_subset_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKA3zovlj45q",
        "outputId": "6cd41f64-5a4e-4506-e2de-4ddd72dccc43"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Test Subset Loss: 0.2916, Test Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pA1fDUYLj7Hl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}